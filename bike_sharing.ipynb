{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Data\n",
    "\n",
    "The Shared Transport (in the pre-pandemic era XD ) is a game changer in urban mobility. This term indicates a demand-driven vehicle sharing method. Nowdays, there are many systems that allow users to rent a vehicle in a particular position and return back to another position, making urban travel easier without using public transport.\n",
    "\n",
    "Bikes, electric bikes, scooters, cars, vans ... it's possible to rent any type of vehicle just using a simple smartphone application, you can access the service and search for the nearest vehicle. All these vehicles are usually connected and they have a huge number of sensors, with the data generated by the vehicles' fleet it's possible to monitor the mobility in the city!\n",
    "\n",
    "In this example we will train a model to predict the rental count using environmental data and fleet status data. Maybe weather conditions, day of week, season, hour of the day, etc ... can affect the rental behaviors. Let's find out.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data available:\n",
    "- instant: record index\n",
    "- dteday : date\n",
    "- season : season (1:Spring, 2:Summer, 3:Autumn, 4:Winter)\n",
    "- yr : year (2011, 2012)\n",
    "- mnth : month ( 1 to 12)\n",
    "- hr : hour (0 to 23)\n",
    "- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)\n",
    "- weekday : day of the week\n",
    "- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n",
    "- weathersit : \n",
    "\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "- temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n",
    "- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n",
    "- hum: Normalized humidity. The values are divided to 100 (max)\n",
    "- windspeed: Normalized wind speed. The values are divided to 67 (max)\n",
    "- casual: count of casual users\n",
    "- registered: count of registered users\n",
    "- cnt: count of total rental bikes including both casual and registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./bike_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.season.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.weather.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick way to understand the available data is to plot the histogram of the numerical attributes\n",
    "# The histo shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis).\n",
    "\n",
    "data.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the histogram analysis it's possible to see that the features have different scale and there are features with a very long tail. These two factors can influence the performance of the machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train split\n",
    "“Your brain is an amazing pattern detection system, which means that it is highly prone to overfitting: if you look at the test set, you may stumble upon some seemingly interesting pattern in the test data that leads you to select a particular kind of Machine Learning model. When you estimate the generalization error using the test set, your estimate will be too optimistic, and you will launch a system that will not perform as well as expected. This is called data snooping bias.”\n",
    "\n",
    "Passi di: Aurélien Géron. “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow”. Apple Books. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“First, make sure you have put the test set aside and you are only exploring the training set. Also, if the training set is very large, you may want to sample an exploration set, to make manipulations easy and fast. In our case, the set is quite small, so you can just work directly on the full set. Let’s create a copy so that you can play with it without harming the training set:”\n",
    "\n",
    "Passi di: Aurélien Géron. “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow”. Apple Books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data = train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a good idea to engineer the time feature because in the quick look it's possible to see that the datset is composed of houly measures\n",
    "\n",
    "tmp = bike_data.datetime.astype('datetime64[ns]')\n",
    "\n",
    "bike_data['year'] = tmp.dt.year\n",
    "bike_data['month'] = tmp.dt.month\n",
    "bike_data['day'] = tmp.dt.day_name()\n",
    "bike_data['hour'] = tmp.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if it's a weekend day or not\n",
    "bike_data['weekend'] = 0\n",
    "bike_data.weekend[bike_data.day == \"Saturday\"] = 1\n",
    "bike_data.weekend[bike_data.day == \"Sunday\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check how the rentcount is releted to the day of the week\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"day\", y=\"count\", data=bike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how it's related to month\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"month\", y=\"count\", data=bike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"season\", y=\"count\", data=bike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"weather\", y=\"count\", data=bike_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset is not too large it's possible to compute the standard correlation coefficient between every pair of features\n",
    "corr_matrix = bike_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlation with the count attribute\n",
    "corr_matrix['count'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of registered users it's very correlated to the rent count, same with the casual number, this is because the total number of users is the sum of this two numbers! \n",
    "I think it's better to remove these two data, how can we know the kind of user a priori? It's better to build a model only using climate and time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.drop(['registered', 'casual'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's plot the correlation with few promising attributes\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"count\", \"temp\", \"atemp\", 'hour', 'month', 'year']\n",
    "\n",
    "scatter_matrix(bike_data[attributes], figsize=(30, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are null values in the column temp, humidity and windspeed. There are 3 options: 1. Drop columns, 2. Drop rows, 3. use some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_num = bike_data.drop(['datetime', 'season', 'weather', 'day'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(bike_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = imputer.transform(bike_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a numpy array\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling categorical \n",
    "bike_cat = bike_data[['season', 'weather', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "bike_1_hot = cat_encoder.fit_transform(bike_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_1_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    tmp = data.datetime.astype('datetime64[ns]')\n",
    "\n",
    "    data['year'] = tmp.dt.year\n",
    "    data['month'] = tmp.dt.month\n",
    "    data['day'] = tmp.dt.day_name()\n",
    "    data['hour'] = tmp.dt.hour\n",
    "\n",
    "    data['weekend'] = 0\n",
    "    data.weekend[data.day == \"Saturday\"] = 1\n",
    "    data.weekend[data.day == \"Sunday\"] = 1\n",
    "\n",
    "    data.drop('datetime', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        # the datetime column is at 0 index\n",
    "        tmp = pd.DatetimeIndex(X[:, 0])\n",
    "        \n",
    "        return np.c_[X[:, 1:], tmp.year, tmp.month, tmp.day_name(), tmp.hour, ((tmp.dayofweek) // 5 == 1).astype(int)]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder()\n",
    "a = attr_adder.transform(train_set.copy().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bla bla for feature scaling\n",
    "\n",
    "“One of the most important transformations you need to apply to your data is feature scaling. With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales.”\n",
    "\n",
    "Passi di: Aurélien Géron. “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow”. Apple Books. \n",
    "    \n",
    "    \n",
    "“There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.”\n",
    "\n",
    "Passi di: Aurélien Géron. “Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow”. Apple Books. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "bike_num_tr = num_pipeline.fit_transform(bike_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.copy().head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('cat', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "test = cat_pipeline.fit_transform(train_set.copy()[['datetime', 'season', 'weather']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(bike_num)\n",
    "cat_attribs = ['season', 'weather', 'day']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        ('attribs_adder', CombinedAttributesAdder(), 'datetime'),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "feature_engineering(bike_data)\n",
    "bike_prepared = full_pipeline.fit_transform(bike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
